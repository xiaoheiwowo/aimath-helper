import numpy as np
import base64
import os
import json
import re
from typing import Dict, List, Optional, Any
import logging
from openai import OpenAI
from PIL import Image
import random
from src.knowledge_base import knowledge_base, KnowledgePoint


class AIProcessor:
    def __init__(self) -> None:
        self.ai_client = OpenAI(
            # api_key=os.getenv("OPENAI_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        self.logger = logging.getLogger(__name__)

    def extract_knowledge_points(self, text: str) -> List[KnowledgePoint]:
        """Extract knowledge points from text based on math curriculum."""
        # è·å–æ‰€æœ‰å¯ç”¨çš„çŸ¥è¯†ç‚¹
        all_knowledge_points = knowledge_base.get_all_knowledge_points()

        # æ„å»ºçŸ¥è¯†ç‚¹åˆ—è¡¨ä¾›AIå‚è€ƒ
        knowledge_points_info = []
        for i, point in enumerate(all_knowledge_points, 1):
            knowledge_points_info.append(f"{i}. {point.outline}: {point.detail}")

        knowledge_points_text = "\n".join(knowledge_points_info)

        # æ„å»ºAIæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°å­¦æ•™å­¦ä¸“å®¶ï¼Œéœ€è¦æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ç²¾å‡†åŒ¹é…ä¸ƒå¹´çº§ç¬¬äºŒç« ã€Šæœ‰ç†æ•°è®¡ç®—ã€‹çš„çŸ¥è¯†ç‚¹ã€‚

å¯ç”¨çš„çŸ¥è¯†ç‚¹åˆ—è¡¨ï¼š
{knowledge_points_text}

ç”¨æˆ·è¦æ±‚ï¼š"{text}"

è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ï¼Œä»ä¸Šè¿°çŸ¥è¯†ç‚¹ä¸­é€‰æ‹©æ‰€æœ‰ç¬¦åˆè¦æ±‚çš„çŸ¥è¯†ç‚¹ã€‚è¦æ±‚ï¼š
1. ç²¾å‡†åŒ¹é…ï¼Œä¸è¦é€‰æ‹©ä¸ç›¸å…³çš„çŸ¥è¯†ç‚¹
2. å¦‚æœç”¨æˆ·è¦æ±‚æ¶‰åŠå¤šä¸ªçŸ¥è¯†ç‚¹ï¼Œè¯·é€‰æ‹©æ‰€æœ‰ç›¸å…³çš„çŸ¥è¯†ç‚¹
3. åªè¿”å›çŸ¥è¯†ç‚¹çš„åºå·ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š1,3,5
4. å¦‚æœæ²¡æœ‰åŒ¹é…çš„çŸ¥è¯†ç‚¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²

è¯·ç›´æ¥è¿”å›åŒ¹é…çš„çŸ¥è¯†ç‚¹åºå·ï¼š"""

        messages = [
            {
                "role": "user",
                "content": prompt,
            }
        ]

        try:
            response = self.ai_client.chat.completions.create(
                model="qwen-plus", messages=messages, max_tokens=100, temperature=0.1
            )

            result = response.choices[0].message.content.strip()

            # è§£æAIè¿”å›çš„åºå·
            if not result:
                return []

            # æå–åºå·
            numbers = re.findall(r"\d+", result)

            matched_points = []
            for num_str in numbers:
                try:
                    index = int(num_str) - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                    if 0 <= index < len(all_knowledge_points):
                        matched_points.append(all_knowledge_points[index])
                except (ValueError, IndexError):
                    continue

            return matched_points

        except Exception as e:
            logging.error(f"AI knowledge point extraction failed: {e}")
            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…ä½œä¸ºå¤‡é€‰
            return knowledge_base.find_matching_knowledge_points(text)

    def parse_practice_markdown(self, practice_markdown: str) -> dict:
        """Parse practice markdown and return practice data."""
        pass

    def parse_student_answer_from_ocr(self, ocr_text: str, practice_data: dict) -> dict:
        """Parse OCR text to student answer format"""
        try:
            prompt = f"""è¯·å°†ä»¥ä¸‹OCRè¯†åˆ«çš„å­¦ç”Ÿç­”é¢˜å†…å®¹è§£æä¸ºç»“æ„åŒ–çš„JSONæ ¼å¼ã€‚

OCRæ–‡æœ¬ï¼š
{ocr_text}

å‚è€ƒç»ƒä¹ è¯•å·ç»“æ„ï¼š
{json.dumps(practice_data, ensure_ascii=False, indent=2)}

è¦æ±‚ï¼š
1. è¯†åˆ«æ‰€æœ‰é¢˜ç›®ç¼–å·å’Œå¯¹åº”çš„å­¦ç”Ÿç­”æ¡ˆ
2. å¯¹äºé€‰æ‹©é¢˜ï¼Œæå–å­¦ç”Ÿé€‰æ‹©çš„é€‰é¡¹ï¼ˆAã€Bã€Cã€Dç­‰ï¼‰
3. å¯¹äºè®¡ç®—é¢˜ï¼Œæå–å­¦ç”Ÿçš„è§£é¢˜æ­¥éª¤å’Œæœ€ç»ˆç­”æ¡ˆ
4. æŒ‰ç…§student_answer.jsonçš„æ ¼å¼è¾“å‡º

è¿”å›JSONæ ¼å¼ï¼š
{{
  "name": "å­¦ç”Ÿå§“åï¼ˆå¦‚æœè¯†åˆ«åˆ°ï¼‰",
  "practice_id": "",
  "sections": [
    {{
      "name": "ä¸€ã€é€‰æ‹©é¢˜",
      "type": "choice",
      "questions": [
        {{
          "id": "é¢˜ç›®ID",
          "answer": {{
            "choice": "A"
          }}
        }}
      ]
    }},
    {{
      "name": "äºŒã€è®¡ç®—é¢˜", 
      "type": "calculation",
      "questions": [
        {{
          "id": "é¢˜ç›®ID",
          "answer": {{
            "solution_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
            "result": "æœ€ç»ˆç­”æ¡ˆ"
          }}
        }}
      ]
    }}
  ]
}}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ã€‚"""

            response = self.ai_client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°å­¦è€å¸ˆï¼Œæ“…é•¿è§£æå­¦ç”Ÿçš„ç­”é¢˜å†…å®¹ã€‚è¯·ä»”ç»†è¯†åˆ«é¢˜ç›®ç¼–å·å’Œç­”æ¡ˆï¼Œå¹¶æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=2000,
            )

            response_text = response.choices[0].message.content

            # æ¸…ç†å“åº”æ–‡æœ¬
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3]
            clean_text = clean_text.strip()

            return json.loads(clean_text)

        except Exception as e:
            self.logger.error(f"è§£æå­¦ç”Ÿç­”æ¡ˆå¤±è´¥: {e}")
            return {"name": "æœªçŸ¥å­¦ç”Ÿ", "practice_id": "", "sections": []}

    def grade_choice_question(
        self, student_answer: str, correct_answer: str, choices: List[Dict]
    ) -> Dict[str, Any]:
        """æ‰¹æ”¹é€‰æ‹©é¢˜"""
        is_correct = student_answer == correct_answer
        result = {
            "is_correct": is_correct,
            "student_answer": student_answer,
            "correct_answer": correct_answer,
            "explanation": "",
        }

        if not is_correct:
            # æ‰¾åˆ°é”™è¯¯é€‰é¡¹çš„è§£é‡Š
            for choice in choices:
                if choice["id"] == student_answer:
                    result["explanation"] = choice.get("explanation", "ç­”æ¡ˆé”™è¯¯")
                    break

        return result

    def grade_calculation_question(
        self,
        student_steps: List[str],
        student_result: str,
        correct_steps: List[Dict],
        correct_answer: str,
    ) -> Dict[str, Any]:
        """æ‰¹æ”¹è®¡ç®—é¢˜"""
        try:
            # ä½¿ç”¨AIåˆ¤æ–­æ¯ä¸ªæ­¥éª¤çš„æ­£ç¡®æ€§
            prompt = f"""è¯·åˆ†æå­¦ç”Ÿçš„è®¡ç®—é¢˜è§£ç­”è¿‡ç¨‹ï¼Œåˆ¤æ–­æ¯ä¸ªæ­¥éª¤æ˜¯å¦æ­£ç¡®ã€‚

å­¦ç”Ÿè§£ç­”æ­¥éª¤ï¼š
{json.dumps(student_steps, ensure_ascii=False, indent=2)}

å­¦ç”Ÿæœ€ç»ˆç­”æ¡ˆï¼š{student_result}

è¦æ±‚ï¼š
1. é€ä¸ªåˆ†æå­¦ç”Ÿè§£ç­”çš„æ¯ä¸ªæ­¥éª¤
2. åˆ¤æ–­æ­¥éª¤æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœä¸æ­£ç¡®è¯·è¯´æ˜é”™è¯¯åŸå› 
3. åˆ¤æ–­æœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®
4. ç‰¹åˆ«æ³¨æ„ç¬¦å·è¿ç®—ã€è¿ç®—é¡ºåºç­‰æ•°å­¦è§„åˆ™

è¿”å›JSONæ ¼å¼ï¼š
{{
  "overall_correct": true/false,
  "final_answer_correct": true/false,
  "steps_analysis": [
    {{
      "step_index": 0,
      "student_step": "å­¦ç”Ÿæ­¥éª¤",
      "is_correct": true/false,
      "explanation": "é”™è¯¯åŸå› æˆ–æ­£ç¡®è¯´æ˜"
    }}
  ],
  "final_answer_explanation": "æœ€ç»ˆç­”æ¡ˆåˆ†æ"
}}"""

            response = self.ai_client.chat.completions.create(
                model="qwen-plus",
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°å­¦è€å¸ˆï¼Œæ“…é•¿åˆ†æå­¦ç”Ÿçš„è§£é¢˜è¿‡ç¨‹ã€‚è¯·ä»”ç»†åˆ†ææ¯ä¸ªæ­¥éª¤çš„æ­£ç¡®æ€§ï¼Œç‰¹åˆ«æ³¨æ„æ•°å­¦è¿ç®—è§„åˆ™ã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=1500,
            )

            response_text = response.choices[0].message.content

            # æ¸…ç†å“åº”æ–‡æœ¬
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3]
            clean_text = clean_text.strip()
            print("### grade_calculation_question\n", prompt, clean_text)
            return json.loads(clean_text)

        except Exception as e:
            self.logger.error(f"æ‰¹æ”¹è®¡ç®—é¢˜å¤±è´¥: {e}")
            return {
                "overall_correct": False,
                "final_answer_correct": False,
                "steps_analysis": [],
                "final_answer_explanation": "æ‰¹æ”¹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯",
            }

    def analyze_error_knowledge_points(
        self, grading_results: List[Dict]
    ) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯çŸ¥è¯†ç‚¹ - ç›´æ¥ä»grading_resultsç»Ÿè®¡"""
        try:
            # ç»Ÿè®¡æ¯ä¸ªçŸ¥è¯†ç‚¹çš„é”™è¯¯æ¬¡æ•°
            knowledge_point_errors = {}

            for result in grading_results:
                # åˆ¤æ–­é¢˜ç›®æ˜¯å¦é”™è¯¯ï¼Œå…¼å®¹é€‰æ‹©é¢˜å’Œè®¡ç®—é¢˜çš„ä¸åŒå­—æ®µ
                question_type = result.get("question_type", "")
                is_incorrect = False

                if question_type == "choice":
                    is_incorrect = not result.get("is_correct", True)
                elif question_type == "calculation":
                    is_incorrect = not result.get("overall_correct", True)
                else:
                    is_incorrect = not result.get("is_correct", True)

                if is_incorrect:
                    # è·å–é¢˜ç›®æ¶‰åŠçš„çŸ¥è¯†ç‚¹
                    knowledge_points = result.get("knowledge_points", [])
                    for kp in knowledge_points:
                        if isinstance(kp, dict):
                            outline = kp.get("outline", "")
                            if outline:
                                if outline not in knowledge_point_errors:
                                    knowledge_point_errors[outline] = {
                                        "outline": outline,
                                        "error_count": 0,
                                        "error_examples": [],
                                    }

                                knowledge_point_errors[outline]["error_count"] += 1

                                # æ”¶é›†é”™è¯¯ç¤ºä¾‹ï¼ˆä»explanationä¸­æå–ï¼‰
                                explanation = result.get("explanation", "")
                                if (
                                    explanation
                                    and explanation
                                    not in knowledge_point_errors[outline][
                                        "error_examples"
                                    ]
                                ):
                                    knowledge_point_errors[outline][
                                        "error_examples"
                                    ].append(explanation)

            if not knowledge_point_errors:
                return {"error_knowledge_points": [], "top_error_points": []}

            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ·»åŠ æ ‡å‡†detailæè¿°
            error_knowledge_points = []
            for outline, data in knowledge_point_errors.items():
                # æŸ¥æ‰¾çŸ¥è¯†åº“ä¸­çš„æ ‡å‡†detailæè¿°
                standard_detail = ""
                for kp in knowledge_base.get_all_knowledge_points():
                    if kp.outline == outline:
                        standard_detail = kp.detail
                        break

                error_knowledge_points.append(
                    {
                        "outline": outline,
                        "detail": standard_detail,
                        "error_count": data["error_count"],
                        "error_examples": data["error_examples"][:3],  # æœ€å¤šä¿ç•™3ä¸ªç¤ºä¾‹
                    }
                )

            # æŒ‰é”™è¯¯æ¬¡æ•°æ’åº
            error_knowledge_points.sort(key=lambda x: x["error_count"], reverse=True)

            # è·å–é”™è¯¯æœ€å¤šçš„å‰ä¸¤ä¸ªçŸ¥è¯†ç‚¹
            top_error_points = error_knowledge_points[:2]

            return {
                "error_knowledge_points": error_knowledge_points,
                "top_error_points": top_error_points,
            }

        except Exception as e:
            self.logger.error(f"åˆ†æé”™è¯¯çŸ¥è¯†ç‚¹å¤±è´¥: {e}")
            return {"error_knowledge_points": [], "top_error_points": []}

    def generate_teaching_suggestions(self, grading_results: List[Dict]) -> str:
        """æ ¹æ®å­¦ç”Ÿç­”é¢˜é”™è¯¯ç±»å‹ç”Ÿæˆè¯¾å ‚è®²è§£å»ºè®®"""
        try:
            # åˆ†æé”™è¯¯ç±»å‹å’Œæ¨¡å¼
            error_analysis = self._analyze_error_patterns(grading_results)

            # ç”Ÿæˆé’ˆå¯¹æ€§çš„æ•™å­¦å»ºè®®
            suggestions = self._generate_targeted_suggestions(error_analysis)

            return suggestions

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ•™å­¦å»ºè®®å¤±è´¥: {e}")
            return "æ ¹æ®ä»¥ä¸Šé”™è¯¯åˆ†æï¼Œå»ºè®®é‡ç‚¹å…³æ³¨é”™è¯¯è¾ƒå¤šçš„çŸ¥è¯†ç‚¹ï¼ŒåŠ å¼ºç›¸å…³ç»ƒä¹ ã€‚"

    def _analyze_error_patterns(self, grading_results: List[Dict]) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼å’Œç±»å‹"""
        error_patterns = {
            "choice_errors": [],
            "calculation_errors": [],
            "common_mistakes": [],
            "knowledge_gaps": [],
        }

        for result in grading_results:
            question_type = result.get("question_type", "")
            is_incorrect = False

            if question_type == "choice":
                is_incorrect = not result.get("is_correct", True)
                if is_incorrect:
                    error_patterns["choice_errors"].append(
                        {
                            "question": result.get("question_text", ""),
                            "student_answer": result.get("student_answer", ""),
                            "correct_answer": result.get("correct_answer", ""),
                            "explanation": result.get("explanation", ""),
                            "knowledge_points": result.get("knowledge_points", []),
                        }
                    )
            elif question_type == "calculation":
                is_incorrect = not result.get("overall_correct", True)
                if is_incorrect:
                    steps_analysis = result.get("steps_analysis", [])
                    error_steps = [
                        step
                        for step in steps_analysis
                        if not step.get("is_correct", True)
                    ]

                    error_patterns["calculation_errors"].append(
                        {
                            "question": result.get("question_text", ""),
                            "student_steps": result.get("student_steps", []),
                            "error_steps": error_steps,
                            "final_answer_correct": result.get(
                                "final_answer_correct", False
                            ),
                            "knowledge_points": result.get("knowledge_points", []),
                        }
                    )

        # åˆ†æå¸¸è§é”™è¯¯æ¨¡å¼
        error_patterns["common_mistakes"] = self._identify_common_mistakes(
            error_patterns
        )
        error_patterns["knowledge_gaps"] = self._identify_knowledge_gaps(
            grading_results
        )

        return error_patterns

    def _identify_common_mistakes(self, error_patterns: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«å¸¸è§é”™è¯¯æ¨¡å¼"""
        common_mistakes = []

        # åˆ†æé€‰æ‹©é¢˜å¸¸è§é”™è¯¯
        choice_errors = error_patterns["choice_errors"]
        if choice_errors:
            # ç»Ÿè®¡é”™è¯¯é€‰é¡¹åˆ†å¸ƒ
            wrong_choices = {}
            for error in choice_errors:
                choice = error.get("student_answer", "")
                if choice in wrong_choices:
                    wrong_choices[choice] += 1
                else:
                    wrong_choices[choice] = 1

            # æ‰¾å‡ºæœ€å¸¸è§çš„é”™è¯¯é€‰é¡¹
            if wrong_choices:
                most_common_wrong = max(wrong_choices.items(), key=lambda x: x[1])
                if most_common_wrong[1] > 1:  # å¦‚æœé”™è¯¯æ¬¡æ•°å¤§äº1
                    common_mistakes.append(
                        f"é€‰æ‹©é¢˜ä¸­é€‰é¡¹{most_common_wrong[0]}è¢«é”™è¯¯é€‰æ‹©{most_common_wrong[1]}æ¬¡"
                    )

        # åˆ†æè®¡ç®—é¢˜å¸¸è§é”™è¯¯
        calculation_errors = error_patterns["calculation_errors"]
        if calculation_errors:
            # ç»Ÿè®¡é”™è¯¯æ­¥éª¤ç±»å‹
            step_error_types = {}
            for error in calculation_errors:
                error_steps = error.get("error_steps", [])
                for step in error_steps:
                    explanation = step.get("explanation", "")
                    if "ç¬¦å·" in explanation:
                        step_error_types["ç¬¦å·é”™è¯¯"] = (
                            step_error_types.get("ç¬¦å·é”™è¯¯", 0) + 1
                        )
                    elif "è¿ç®—é¡ºåº" in explanation or "ä¼˜å…ˆçº§" in explanation:
                        step_error_types["è¿ç®—é¡ºåºé”™è¯¯"] = (
                            step_error_types.get("è¿ç®—é¡ºåºé”™è¯¯", 0) + 1
                        )
                    elif "è®¡ç®—" in explanation:
                        step_error_types["è®¡ç®—é”™è¯¯"] = (
                            step_error_types.get("è®¡ç®—é”™è¯¯", 0) + 1
                        )

            # æ·»åŠ æœ€å¸¸è§çš„é”™è¯¯ç±»å‹
            for error_type, count in step_error_types.items():
                if count > 1:
                    common_mistakes.append(f"è®¡ç®—é¢˜ä¸­{error_type}å‡ºç°{count}æ¬¡")

        return common_mistakes

    def _identify_knowledge_gaps(self, grading_results: List[Dict]) -> List[str]:
        """è¯†åˆ«çŸ¥è¯†ç›²ç‚¹"""
        knowledge_gaps = []

        # ç»Ÿè®¡é”™è¯¯çŸ¥è¯†ç‚¹
        error_knowledge_points = {}
        for result in grading_results:
            question_type = result.get("question_type", "")
            is_incorrect = False

            if question_type == "choice":
                is_incorrect = not result.get("is_correct", True)
            elif question_type == "calculation":
                is_incorrect = not result.get("overall_correct", True)

            if is_incorrect:
                knowledge_points = result.get("knowledge_points", [])
                for kp in knowledge_points:
                    if isinstance(kp, dict):
                        outline = kp.get("outline", "")
                        if outline:
                            error_knowledge_points[outline] = (
                                error_knowledge_points.get(outline, 0) + 1
                            )

        # æ‰¾å‡ºé”™è¯¯æœ€å¤šçš„çŸ¥è¯†ç‚¹
        if error_knowledge_points:
            sorted_errors = sorted(
                error_knowledge_points.items(), key=lambda x: x[1], reverse=True
            )
            for outline, count in sorted_errors[:3]:  # å–å‰3ä¸ª
                if count > 1:  # é”™è¯¯æ¬¡æ•°å¤§äº1
                    knowledge_gaps.append(f"{outline}ç›¸å…³é¢˜ç›®é”™è¯¯{count}æ¬¡")

        return knowledge_gaps

    def _generate_targeted_suggestions(self, error_patterns: Dict[str, Any]) -> str:
        """ç”Ÿæˆé’ˆå¯¹æ€§çš„æ•™å­¦å»ºè®®"""
        suggestions = []
        suggestion_count = 1

        # åŸºäºçŸ¥è¯†ç›²ç‚¹ç”Ÿæˆå»ºè®®ï¼ˆæœ€é‡è¦çš„ï¼‰
        knowledge_gaps = error_patterns["knowledge_gaps"]
        if knowledge_gaps:
            gap_topic = knowledge_gaps[0].split("ç›¸å…³")[0]
            suggestions.append(
                f"{suggestion_count}. é‡ç‚¹çªç ´ï¼šé’ˆå¯¹{gap_topic}è¿›è¡Œä¸“é¡¹è®­ç»ƒï¼Œé€šè¿‡å…¸å‹ä¾‹é¢˜åå¤ç»ƒä¹ ã€‚"
            )
            suggestion_count += 1

        # åŸºäºå¸¸è§é”™è¯¯æ¨¡å¼ç”Ÿæˆå»ºè®®
        common_mistakes = error_patterns["common_mistakes"]
        if common_mistakes:
            if any("ç¬¦å·é”™è¯¯" in mistake for mistake in common_mistakes):
                suggestions.append(
                    f"{suggestion_count}. ç¬¦å·å¼ºåŒ–ï¼šä¸“é—¨ç»ƒä¹ ç¬¦å·è¿ç®—ï¼Œè¦æ±‚å­¦ç”Ÿå…ˆç¡®å®šç¬¦å·å†è®¡ç®—ï¼Œé¿å…ç¬¦å·é”™è¯¯ã€‚"
                )
                suggestion_count += 1
            if any("è¿ç®—é¡ºåºé”™è¯¯" in mistake for mistake in common_mistakes):
                suggestions.append(
                    f"{suggestion_count}. å£è¯€è®°å¿†ï¼šæ€»ç»“è¿ç®—é¡ºåºå£è¯€ï¼ˆå¦‚'å…ˆæ‹¬å·ï¼Œå†ä¹˜æ–¹ï¼Œä¹˜é™¤åŠ å‡ä¸ä¹±å¿™'ï¼‰ï¼Œå¸®åŠ©å­¦ç”Ÿè®°å¿†ã€‚"
                )
                suggestion_count += 1
            if any("è®¡ç®—é”™è¯¯" in mistake for mistake in common_mistakes):
                suggestions.append(
                    f"{suggestion_count}. æ­¥éª¤åŒ–æ•™å­¦ï¼šå¸¦ç€å­¦ç”Ÿä¸€æ­¥ä¸€æ­¥æ¼”ç®—ï¼Œè¦æ±‚å†™æ¸…æ¯ä¸€æ­¥ï¼Œé¿å…å¿ƒç®—è·³æ­¥ã€‚"
                )
                suggestion_count += 1

        # åŸºäºå…·ä½“é”™è¯¯ç±»å‹ç”Ÿæˆå»ºè®®
        choice_errors = error_patterns["choice_errors"]
        calculation_errors = error_patterns["calculation_errors"]

        if choice_errors and calculation_errors:
            suggestions.append(
                f"{suggestion_count}. é”™å› è®²è§£ï¼šç”¨å­¦ç”Ÿçš„å…¸å‹é”™é¢˜åšåä¾‹åˆ†æï¼Œè®©ä»–ä»¬è‡ªå·±æ‰¾é”™è¯¯å¹¶æ”¹æ­£ã€‚"
            )
            suggestion_count += 1
        elif choice_errors:
            suggestions.append(
                f"{suggestion_count}. æ¦‚å¿µè¾¨æï¼šé€šè¿‡å¯¹æ¯”åˆ†ææ˜“æ··æ·†æ¦‚å¿µï¼Œè®¾è®¡å˜å¼ç»ƒä¹ åŠ æ·±ç†è§£ã€‚"
            )
            suggestion_count += 1
        elif calculation_errors:
            suggestions.append(
                f"{suggestion_count}. éªŒç®—ä¹ æƒ¯ï¼šåŸ¹å…»å­¦ç”Ÿé€æ­¥éªŒç®—çš„ä¹ æƒ¯ï¼Œæé«˜è®¡ç®—å‡†ç¡®æ€§ã€‚"
            )
            suggestion_count += 1

        # å¦‚æœæ²¡æœ‰å…·ä½“é”™è¯¯æ¨¡å¼ï¼Œæä¾›é€šç”¨å»ºè®®
        if not suggestions:
            suggestions.append(
                f"{suggestion_count}. åŸºç¡€å·©å›ºï¼šåŠ å¼ºåŸºç¡€æ¦‚å¿µæ•™å­¦ï¼Œé€šè¿‡åå¤ç»ƒä¹ å·©å›ºçŸ¥è¯†ç‚¹ã€‚"
            )

        return "\n".join(suggestions)

    def ocr_practice(self, image_path: str) -> Dict[str, str]:
        """Extract text using Qwen-VL-OCR model.

        Args:
            image_path: Path to the input image

        Returns:
            Dictionary containing OCR results from AI model
        """
        try:
            # Encode image to base64
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode("utf-8")

            # Log image processing without exposing image data
            self.logger.debug(
                f"Processing image: {image_path}, size: {len(base64_image)} characters"
            )

            # Create prompt for mathematical OCR
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """è¯·ä»”ç»†è¯†åˆ«è¿™å¼ æ•°å­¦ä½œä¸šå›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å’Œæ•°å­¦è¡¨è¾¾å¼ã€‚è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«é¢˜ç›®ç¼–å·å’Œæ•°å­—ã€è¿ç®—ç¬¦å·ã€åˆ†æ•°ã€ç­‰å·ç­‰æ•°å­¦ç¬¦å·
2. æ•°å­¦è¡¨è¾¾å¼ä½¿ç”¨ latex è¯­æ³•ã€‚
3. è¯†åˆ«ä¸­æ–‡é¢˜ç›®æè¿°å’Œè§£ç­”è¿‡ç¨‹
4. å¯¹äºæ‰‹å†™å†…å®¹ï¼Œè¯·å°½å¯èƒ½å‡†ç¡®è¯†åˆ«
5. æŒ‰ç…§åŸå›¾çš„é¡ºåºè¾“å‡ºå†…å®¹

è¯·ç›´æ¥è¾“å‡ºè¯†åˆ«çš„æ–‡å­—å†…å®¹ï¼Œä¸è¦æ·»åŠ é¢å¤–çš„è§£é‡Šã€‚""",
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ]

            # Call Qwen-VL-OCR model
            response = self.ai_client.chat.completions.create(
                model="qwen-vl-ocr", messages=messages, max_tokens=2000, temperature=0.1
            )

            raw_text = response.choices[0].message.content

            # AI OCR typically has high confidence when it works
            confidence = 85.0 if raw_text and len(raw_text.strip()) > 10 else 30.0

            return {
                "raw_text": raw_text.strip(),
                "confidence": confidence,
                "method": "ai_ocr",
                "model": "qwen-vl-ocr",
            }

        except Exception as e:
            return {
                "raw_text": "",
                "confidence": 0,
                "error": str(e),
                "method": "ai_ocr_failed",
            }

    def _parse_with_rules(self, ocr_text: str) -> List[Dict]:
        """Use rule-based parsing as fallback"""
        # ç®€å•çš„è§„åˆ™è§£æï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

    def detect_question_areas(
        self,
        image_path: str,
        practice_data: Dict[str, Any] = None,
        resize_size: int = 1000,
    ) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„é¢˜ç›®åŒºåŸŸï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            practice_data: ç»ƒä¹ æ•°æ®ï¼ˆå¯é€‰ï¼Œä¸ä½¿ç”¨ï¼‰
            resize_size: å›¾ç‰‡ç¼©æ”¾å°ºå¯¸ï¼ˆé»˜è®¤ 1000x1000ï¼‰

        Returns:
            é¢˜ç›®åŒºåŸŸä¿¡æ¯åˆ—è¡¨ï¼ŒåŒ…å«é¢˜å·ã€ä½ç½®åæ ‡ç­‰ï¼ˆåƒç´ åæ ‡ï¼‰
            æ³¨æ„ï¼šåæ ‡æ˜¯åŸºäº resize åçš„å›¾ç‰‡ï¼ŒåŒ…å« original_size å’Œ resized_size ä¿¡æ¯ç”¨äºè¿˜åŸ
        """
        try:
            # è·å–åŸå§‹å›¾ç‰‡å°ºå¯¸
            with Image.open(image_path) as img:
                original_width, original_height = img.size

            # Resize å›¾ç‰‡
            resized_path = self._resize_image(image_path, resize_size)

            # ç¼–ç å›¾ç‰‡ä¸º base64
            with open(resized_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode("utf-8")

            # ç®€åŒ–çš„ prompt
            prompt = """å®šä½è¯•å·å›¾ç‰‡ä¸­æ‰€æœ‰é¢˜ç›®åŒºåŸŸï¼Œè¾“å‡ºä¸ºäºŒç»´çº¿æ¡†åæ ‡ï¼ˆåƒç´ åæ ‡ï¼‰ï¼ŒæŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¿”å›ï¼š

{
  "question_areas": [
    {
      "question_number": "é¢˜ç›®ç¼–å·",
      "bbox_2d": [x1, y1, x2, y2]
    }
  ]
}

è¦æ±‚ï¼š
- bbox_2d æ˜¯é¢˜ç›®åŒºåŸŸçš„çŸ©å½¢åæ ‡ï¼Œ[x1, y1, x2, y2] ä¸ºåƒç´ åæ ‡ï¼ˆæ•´æ•°ï¼‰
- question_number ä¸ºé¢˜ç›®ç¼–å·ï¼ˆå¦‚ "1", "2" ç­‰ï¼‰
- åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–è¯´æ˜"""

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt,
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ]

            self.logger.info(
                f"ä½¿ç”¨ç®€åŒ– prompt æ£€æµ‹é¢˜ç›®åŒºåŸŸï¼ŒåŸå§‹å°ºå¯¸: {original_width}x{original_height}, resize å°ºå¯¸: {resize_size}x{resize_size}"
            )

            # è°ƒç”¨ AI æ¨¡å‹ï¼ˆä¸ä½¿ç”¨ JSON Schemaï¼‰
            response = self.ai_client.chat.completions.create(
                model="qwen-vl-max",
                messages=messages,
                max_tokens=2000,
                temperature=0.1,
            )

            response_text = response.choices[0].message.content
            self.logger.info(f"AIæ¨¡å‹è¿”å›ç»“æœé•¿åº¦: {len(response_text)} å­—ç¬¦")

            # æ¸…ç† markdown ä»£ç å—æ ‡è®°
            response_text = response_text.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            response_text = response_text.strip()

            # è§£æ JSON
            result = json.loads(response_text)
            question_areas = result.get("question_areas", [])

            # ä¸ºæ¯ä¸ªåŒºåŸŸæ·»åŠ é»˜è®¤å­—æ®µå’Œå°ºå¯¸ä¿¡æ¯
            for area in question_areas:
                # æ·»åŠ å°ºå¯¸ä¿¡æ¯ç”¨äºåæ ‡è½¬æ¢
                area["original_size"] = [original_width, original_height]
                area["resized_size"] = [resize_size, resize_size]

                if "answer_bbox_2d" not in area:
                    # é»˜è®¤ç­”æ¡ˆåŒºåŸŸä¸ºé¢˜ç›®åŒºåŸŸçš„ä¸‹åŠéƒ¨åˆ†
                    bbox = area.get("bbox_2d", [0, 0, 0, 0])
                    if len(bbox) == 4:
                        x1, y1, x2, y2 = bbox
                        answer_y1 = y1 + int((y2 - y1) * 0.6)
                        area["answer_bbox_2d"] = [x1, answer_y1, x2, y2]
                    else:
                        area["answer_bbox_2d"] = [0, 0, 0, 0]

                if "question_type" not in area:
                    area["question_type"] = "unknown"
                if "confidence" not in area:
                    area["confidence"] = 0.8

            self.logger.info(f"æ£€æµ‹åˆ° {len(question_areas)} ä¸ªé¢˜ç›®åŒºåŸŸ")
            if question_areas:
                for i, area in enumerate(question_areas):
                    self.logger.info(
                        f"é¢˜ç›® {i + 1}: {area.get('question_number', 'N/A')} - åæ ‡(resize): {area.get('bbox_2d', 'N/A')}"
                    )
            else:
                self.logger.warning("æœªæ£€æµ‹åˆ°ä»»ä½•é¢˜ç›®åŒºåŸŸ")

            return question_areas

        except json.JSONDecodeError as e:
            self.logger.error(f"JSON è§£æå¤±è´¥: {e}")
            self.logger.error(
                f"å“åº”å†…å®¹: {response_text[:500] if 'response_text' in locals() else 'N/A'}"
            )
            return []
        except Exception as e:
            self.logger.error(f"é¢˜ç›®åŒºåŸŸæ£€æµ‹å¤±è´¥: {e}")
            import traceback

            self.logger.error(traceback.format_exc())
            return []

    def _resize_image(self, image_path: str, target_size: int = 1000) -> str:
        """
        å°†å›¾ç‰‡ç¼©æ”¾ä¸ºæŒ‡å®šå°ºå¯¸ï¼ˆæ­£æ–¹å½¢ï¼‰

        Args:
            image_path: åŸå§‹å›¾ç‰‡è·¯å¾„
            target_size: ç›®æ ‡å°ºå¯¸ï¼ˆé»˜è®¤ 1000ï¼‰

        Returns:
            ç¼©æ”¾åçš„å›¾ç‰‡è·¯å¾„
        """
        img = Image.open(image_path)
        original_size = img.size

        # ç›´æ¥ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸ï¼ˆä¸ä¿æŒå®½é«˜æ¯”ï¼‰
        resized_img = img.resize((target_size, target_size), Image.Resampling.LANCZOS)

        # ä¿å­˜ç¼©æ”¾åçš„å›¾ç‰‡ï¼ˆä¸´æ—¶æ–‡ä»¶ï¼‰
        import tempfile

        # è·å–æ–‡ä»¶æ‰©å±•å
        _, ext = os.path.splitext(image_path)
        if not ext:
            ext = ".jpg"

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_fd, temp_path = tempfile.mkstemp(suffix=ext, prefix="resized_")
        os.close(temp_fd)

        # ä¿å­˜å›¾ç‰‡
        resized_img.save(temp_path, quality=95)

        self.logger.info(
            f"å›¾ç‰‡å·²ç¼©æ”¾: {original_size} -> ({target_size}, {target_size})"
        )
        self.logger.debug(f"ç¼©æ”¾åå›¾ç‰‡è·¯å¾„: {temp_path}")

        return temp_path

    @staticmethod
    def convert_coords_to_original(
        bbox: List[int], original_size: List[int], resized_size: List[int]
    ) -> List[int]:
        """
        å°† resize åçš„åæ ‡è½¬æ¢å›åŸå§‹å›¾ç‰‡åæ ‡

        Args:
            bbox: resize åçš„åæ ‡ [x1, y1, x2, y2]
            original_size: åŸå§‹å›¾ç‰‡å°ºå¯¸ [width, height]
            resized_size: resize åçš„å°ºå¯¸ [width, height]

        Returns:
            åŸå§‹å›¾ç‰‡åæ ‡ [x1, y1, x2, y2]
        """
        if len(bbox) != 4 or len(original_size) != 2 or len(resized_size) != 2:
            print(
                f"âš ï¸ åæ ‡è½¬æ¢å‚æ•°é”™è¯¯: bbox={bbox}, orig={original_size}, resized={resized_size}"
            )
            return bbox

        x1, y1, x2, y2 = bbox
        orig_w, orig_h = original_size
        resized_w, resized_h = resized_size

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = orig_w / resized_w
        scale_y = orig_h / resized_h

        print(f"ğŸ”§ åæ ‡è½¬æ¢:")
        print(f"   è¾“å…¥åæ ‡: [{x1}, {y1}, {x2}, {y2}]")
        print(f"   åŸå§‹å°ºå¯¸: {orig_w} x {orig_h}")
        print(f"   Resizeå°ºå¯¸: {resized_w} x {resized_h}")
        print(f"   ç¼©æ”¾æ¯”ä¾‹: x={scale_x:.2f}, y={scale_y:.2f}")

        # è½¬æ¢åæ ‡
        orig_x1 = int(x1 * scale_x)
        orig_y1 = int(y1 * scale_y)
        orig_x2 = int(x2 * scale_x)
        orig_y2 = int(y2 * scale_y)

        print(f"   è¾“å‡ºåæ ‡: [{orig_x1}, {orig_y1}, {orig_x2}, {orig_y2}]")

        return [orig_x1, orig_y1, orig_x2, orig_y2]

    @staticmethod
    def convert_question_areas_to_original(
        question_areas: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        å°†æ£€æµ‹ç»“æœä¸­çš„æ‰€æœ‰åæ ‡è½¬æ¢å›åŸå§‹å›¾ç‰‡åæ ‡

        Args:
            question_areas: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼ˆåŒ…å« original_size å’Œ resized_sizeï¼‰

        Returns:
            è½¬æ¢åçš„æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        converted_areas = []

        for area in question_areas:
            converted_area = area.copy()

            original_size = area.get("original_size")
            resized_size = area.get("resized_size")

            if original_size and resized_size:
                # è½¬æ¢é¢˜ç›®åŒºåŸŸåæ ‡
                if "bbox_2d" in area:
                    converted_area["bbox_2d"] = AIProcessor.convert_coords_to_original(
                        area["bbox_2d"], original_size, resized_size
                    )

                # è½¬æ¢ç­”æ¡ˆåŒºåŸŸåæ ‡
                if "answer_bbox_2d" in area:
                    converted_area["answer_bbox_2d"] = (
                        AIProcessor.convert_coords_to_original(
                            area["answer_bbox_2d"], original_size, resized_size
                        )
                    )

            converted_areas.append(converted_area)

        return converted_areas

    def get_question_positions_for_grading(
        self,
        image_width: int,
        image_height: int,
        question_areas: Optional[List[Dict[str, Any]]] = None,
        image_path: Optional[str] = None,
        practice_data: Optional[Dict[str, Any]] = None,
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨äºæ‰¹æ”¹æ ‡è®°çš„é¢˜ç›®ä½ç½®ä¿¡æ¯

        Args:
            image_width: ç›®æ ‡å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰- é€šå¸¸æ˜¯åŸå§‹å›¾ç‰‡å°ºå¯¸
            image_height: ç›®æ ‡å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰- é€šå¸¸æ˜¯åŸå§‹å›¾ç‰‡å°ºå¯¸
            question_areas: å·²æ£€æµ‹çš„é¢˜ç›®åŒºåŸŸåˆ—è¡¨ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            image_path: å›¾ç‰‡è·¯å¾„ï¼ˆå½“question_areasä¸ºNoneæ—¶ä½¿ç”¨ï¼‰
            practice_data: ç»ƒä¹ æ•°æ®ï¼ˆå½“question_areasä¸ºNoneæ—¶ä½¿ç”¨ï¼‰

        Returns:
            ç”¨äºæ‰¹æ”¹æ ‡è®°çš„ä½ç½®ä¿¡æ¯åˆ—è¡¨ï¼ˆåæ ‡å·²è½¬æ¢ä¸ºç›®æ ‡å›¾ç‰‡å°ºå¯¸ï¼‰
        """
        # å¦‚æœæ²¡æœ‰æä¾›question_areasï¼Œåˆ™å°è¯•æ£€æµ‹
        if question_areas is None:
            if image_path and practice_data:
                question_areas = self.detect_question_areas(image_path, practice_data)
            else:
                self.logger.warning(
                    "æœªæä¾›question_areasï¼Œä¸”ç¼ºå°‘image_pathæˆ–practice_data"
                )
                return []

        if not question_areas:
            self.logger.warning("question_areasä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ‰¹æ”¹ä½ç½®")
            return []

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åæ ‡è½¬æ¢
        # å¦‚æœ question_areas åŒ…å« original_size å’Œ resized_sizeï¼Œè¯´æ˜æ˜¯ resize åçš„åæ ‡
        needs_conversion = False
        if (
            question_areas
            and "original_size" in question_areas[0]
            and "resized_size" in question_areas[0]
        ):
            original_size = question_areas[0]["original_size"]
            resized_size = question_areas[0]["resized_size"]

            self.logger.info(f"åŸå§‹å›¾ç‰‡å°ºå¯¸ï¼ˆä»æ£€æµ‹ç»“æœï¼‰: {original_size}")
            self.logger.info(f"Resize åå°ºå¯¸ï¼ˆä»æ£€æµ‹ç»“æœï¼‰: {resized_size}")
            self.logger.info(f"ç›®æ ‡å°ºå¯¸ï¼ˆå‚æ•°ä¼ å…¥ï¼‰: ({image_width}, {image_height})")

            # æ‰“å°ç¬¬ä¸€ä¸ªåæ ‡ä½œä¸ºç¤ºä¾‹
            if question_areas:
                sample_bbox = question_areas[0].get("bbox_2d", [])
                self.logger.info(f"ç¤ºä¾‹åæ ‡ï¼ˆè½¬æ¢å‰ï¼‰: {sample_bbox}")

            # æ£€æŸ¥ç›®æ ‡å°ºå¯¸æ˜¯å¦ä¸ resized_size ä¸€è‡´
            if (image_width, image_height) != tuple(resized_size):
                needs_conversion = True
                self.logger.info(
                    f"æ£€æµ‹åˆ°åæ ‡éœ€è¦è½¬æ¢: resize({resized_size}) -> target({image_width}x{image_height})"
                )
            else:
                self.logger.info("ç›®æ ‡å°ºå¯¸ä¸ resize å°ºå¯¸ä¸€è‡´ï¼Œæ— éœ€è½¬æ¢")

        # å¦‚æœéœ€è¦è½¬æ¢ï¼Œå…ˆè½¬æ¢åæ ‡
        if needs_conversion:
            # è½¬æ¢åˆ°åŸå§‹å°ºå¯¸
            question_areas_converted = self.convert_question_areas_to_original(
                question_areas
            )

            # æ‰“å°è½¬æ¢åçš„åæ ‡
            if question_areas_converted:
                sample_bbox_converted = question_areas_converted[0].get("bbox_2d", [])
                self.logger.info(f"ç¤ºä¾‹åæ ‡ï¼ˆè½¬æ¢åï¼‰: {sample_bbox_converted}")
        else:
            question_areas_converted = question_areas

        # è½¬æ¢ä¸ºæ‰¹æ”¹æ ‡è®°éœ€è¦çš„æ ¼å¼
        grading_positions = []

        for area in question_areas_converted:
            bbox_2d = area.get("bbox_2d", [0, 0, 0, 0])
            answer_bbox_2d = area.get("answer_bbox_2d", [0, 0, 0, 0])

            # bbox_2d ç°åœ¨æ˜¯ç›®æ ‡å°ºå¯¸çš„åƒç´ åæ ‡ï¼Œç›´æ¥ä½¿ç”¨
            question_x1 = bbox_2d[0]
            question_y1 = bbox_2d[1]
            question_x2 = bbox_2d[2]
            question_y2 = bbox_2d[3]

            # æ ‡è®°ä½ç½®ï¼šæ”¾åœ¨é¢˜ç›®åŒºåŸŸçš„å·¦ä¸‹è§’
            # x = question_x1
            # y = question_y2

            x = (question_x1 + question_x2) / 2 + random.randint(0, 100)
            y = (question_y1 + question_y2) / 2

            self.logger.debug(f"æ‰¹æ”¹æ ‡è®°ä½ç½®: ({x}, {y})")

            grading_position = {
                "question_number": area.get("question_number", ""),
                "question_type": area.get("question_type", ""),
                "bbox_2d": bbox_2d,
                "answer_bbox_2d": answer_bbox_2d,
                "x": int(x),
                "y": int(y),
                "width": 100,  # æ ‡è®°åŒºåŸŸå®½åº¦
                "height": 100,  # æ ‡è®°åŒºåŸŸé«˜åº¦
                "confidence": area.get("confidence", 0.5),
            }

            grading_positions.append(grading_position)

        return grading_positions

    def save_question_positions_to_sections(
        self,
        question_areas: List[Dict[str, Any]],
        student_answers: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        å°†é¢˜ç›®ä½ç½®ä¿¡æ¯ä¿å­˜åˆ°sections[].questions[].positionsä¸­

        æ–°é€»è¾‘ï¼šæŒ‰ç…§ student_answers ä¸­é¢˜ç›®çš„æ•´ä½“é¡ºåºè¿›è¡ŒåŒ¹é…
        åªè¦ question_areas çš„æ•°é‡ç­‰äºé¢˜ç›®æ€»æ•°ï¼Œå°±æŒ‰é¡ºåºä¸€ä¸€å¯¹åº”

        Args:
            question_areas: AIæ£€æµ‹åˆ°çš„é¢˜ç›®åŒºåŸŸä¿¡æ¯ï¼ˆä¸åŒ…å«question_idï¼Œä½†æŒ‰é¡ºåºæ’åˆ—ï¼‰
            student_answers: å­¦ç”Ÿç­”æ¡ˆæ•°æ®

        Returns:
            æ›´æ–°åçš„å­¦ç”Ÿç­”æ¡ˆæ•°æ®
        """
        # ä¸ºæ¯ä¸ªå­¦ç”Ÿç­”æ¡ˆæ·»åŠ ä½ç½®ä¿¡æ¯
        for student_answer in student_answers:
            sections = student_answer.get("sections", [])

            # è®¡ç®—æ€»é¢˜ç›®æ•°
            total_questions = sum(
                len(section.get("questions", [])) for section in sections
            )

            print(
                f"ğŸ“ ä¿å­˜ä½ç½®ä¿¡æ¯: é¢˜ç›®æ€»æ•° {total_questions}, ä½ç½®ä¿¡æ¯æ•°é‡ {len(question_areas)}"
            )

            # å¦‚æœä½ç½®ä¿¡æ¯æ•°é‡ä¸é¢˜ç›®æ•°é‡åŒ¹é…ï¼ŒæŒ‰é¡ºåºå¯¹åº”
            if len(question_areas) == total_questions:
                print("âœ… æ•°é‡åŒ¹é…ï¼ŒæŒ‰é¡ºåºä¿å­˜ä½ç½®ä¿¡æ¯")

                # æŒ‰é¡ºåºéå†æ‰€æœ‰é¢˜ç›®
                position_index = 0
                for section in sections:
                    questions = section.get("questions", [])
                    for question in questions:
                        if position_index < len(question_areas):
                            area = question_areas[position_index]
                            question["positions"] = {
                                "bbox_2d": area.get("bbox_2d", [0, 0, 0, 0]),
                                "answer_bbox_2d": area.get(
                                    "answer_bbox_2d", [0, 0, 0, 0]
                                ),
                                "confidence": area.get("confidence", 0.5),
                            }
                            print(f"  é¢˜ç›® {position_index + 1}: ä¿å­˜ä½ç½®ä¿¡æ¯")
                            position_index += 1
            else:
                # å¦‚æœæ•°é‡ä¸åŒ¹é…ï¼Œå›é€€åˆ°æ—§çš„åŒ¹é…é€»è¾‘ï¼ˆæŒ‰é¢˜ç›®ç±»å‹å’Œåºå·ï¼‰
                print("âš ï¸ æ•°é‡ä¸åŒ¹é…ï¼Œä½¿ç”¨æ—§çš„åŒ¹é…é€»è¾‘ï¼ˆæŒ‰é¢˜ç›®ç±»å‹å’Œåºå·ï¼‰")

                # æŒ‰é¢˜ç›®ç±»å‹å’Œåºå·ç»„ç»‡ä½ç½®ä¿¡æ¯
                positions_by_type_and_number = {}
                for area in question_areas:
                    question_type = area.get("question_type", "")
                    question_number = area.get("question_number", "")

                    if question_type not in positions_by_type_and_number:
                        positions_by_type_and_number[question_type] = {}

                    positions_by_type_and_number[question_type][question_number] = {
                        "bbox_2d": area.get("bbox_2d", [0, 0, 0, 0]),
                        "answer_bbox_2d": area.get("answer_bbox_2d", [0, 0, 0, 0]),
                        "confidence": area.get("confidence", 0.5),
                    }

                # å°†ä½ç½®ä¿¡æ¯æ·»åŠ åˆ°å¯¹åº”çš„é¢˜ç›®ä¸­
                for section in sections:
                    section_type = section.get("type", "")
                    questions = section.get("questions", [])

                    if section_type in positions_by_type_and_number:
                        type_positions = positions_by_type_and_number[section_type]

                        for i, question in enumerate(questions):
                            question_number = str(i + 1)  # é¢˜ç›®åºå·ä»1å¼€å§‹

                            if question_number in type_positions:
                                question["positions"] = type_positions[question_number]

        return student_answers

    def _build_question_info(self, practice_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºé¢˜ç›®ä¿¡æ¯å­—å…¸ä¾›AIå‚è€ƒ"""
        sections_info = []
        total_questions = 0

        for section in practice_data.get("sections", []):
            section_name = section.get("name", "")
            section_type = section.get("type", "")
            questions = section.get("questions", [])
            question_count = len(questions)
            total_questions += question_count

            section_data = {
                "name": section_name,
                "type": section_type,
                "count": question_count,
                "questions": [],
            }

            for i, question in enumerate(questions, 1):
                question_id = question.get("id", "")
                question_text = question.get("question", "")

                # æˆªå–é¢˜ç›®æ–‡æœ¬çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºå‚è€ƒ
                short_question = (
                    question_text[:100] + "..."
                    if len(question_text) > 100
                    else question_text
                )

                section_data["questions"].append(
                    {"number": i, "id": question_id, "preview": short_question}
                )

            sections_info.append(section_data)

        return {"total_questions": total_questions, "sections": sections_info}

    def _build_detection_prompt(
        self, question_info: Dict[str, Any], image_width: int, image_height: int
    ) -> str:
        """æ„å»ºæ£€æµ‹prompt"""
        # æ„å»ºé¢˜ç›®æ¦‚è¿°
        total_questions = question_info.get("total_questions", 0)
        sections = question_info.get("sections", [])

        # æ„å»ºè¯¦ç»†çš„é¢˜ç›®ä¿¡æ¯
        sections_text = []
        for section in sections:
            section_name = section.get("name", "")
            section_type = section.get("type", "")
            question_count = section.get("count", 0)
            sections_text.append(
                f"- {section_name}ï¼š{question_count} é“é¢˜ï¼ˆç±»å‹ï¼š{section_type}ï¼‰"
            )

        sections_summary = "\n".join(sections_text)

        print("sections_summary", sections_summary, "total_questions", total_questions)

        return f"""è·å–å›¾ç‰‡ä¸­æ‰€æœ‰é¢˜ç›®åŒºåŸŸçš„ä½ç½®åæ ‡ï¼Œå…±æœ‰ {total_questions} é“é¢˜   
å›¾ç‰‡å°ºå¯¸ï¼š{image_width} x {image_height} åƒç´ 

è¯•å·ç»“æ„ï¼š
{sections_summary}

å†…å®¹ï¼š
1. é¢˜ç›®å†…å®¹ä½ç½®ä¿¡æ¯ï¼šè¯†åˆ«æ¯ä¸ªé¢˜ç›®åŒºåŸŸçš„å…·ä½“ä½ç½®åæ ‡
2. å­¦ç”Ÿç­”é¢˜ä½ç½®ä¿¡æ¯ï¼šè¯†åˆ«åœ¨æ¯ä¸ªé¢˜ç›®åŒºåŸŸä¸­å­¦ç”Ÿå¡«å†™ç­”æ¡ˆçš„ä½ç½®ä¿¡æ¯ã€‚
3. è¯†åˆ«é¢˜ç›®ç±»å‹ï¼šé€‰æ‹©é¢˜ï¼ˆchoiceï¼‰æˆ–è®¡ç®—é¢˜ï¼ˆcalculationï¼‰

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "question_areas": [
    {{
      "question_number": "é¢˜ç›®ç¼–å·ï¼ˆå¦‚1ã€2ã€ä¸€ã€äºŒç­‰ï¼‰",
      "question_type": "é¢˜ç›®ç±»å‹ï¼ˆchoice/calculationï¼‰",
      "bbox_2d": [x1, y1, x2, y2],
      "answer_bbox_2d": [x1, y1, x2, y2],
      "confidence": "è¯†åˆ«ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰"
    }}
  ]
}}

è¦æ±‚ï¼š
1. åæ ‡ä½¿ç”¨ç»å¯¹åƒç´ åæ ‡ï¼ˆæ•´æ•°ï¼‰ï¼ŒèŒƒå›´æ˜¯ 0 åˆ° {image_width}ï¼ˆå®½åº¦ï¼‰å’Œ 0 åˆ° {image_height}ï¼ˆé«˜åº¦ï¼‰
2. **å¿…é¡»è¯†åˆ«å‡ºæ‰€æœ‰ {total_questions} é“é¢˜ç›®ï¼Œquestion_areas æ•°ç»„çš„é•¿åº¦åº”è¯¥ç­‰äº {total_questions}**
   - ä¸ºæ¯é“é¢˜ç¡®å®šä¸€ä¸ªçŸ©å½¢åŒºåŸŸï¼ŒåŒ…å«é¢˜ç›®å’Œç­”é¢˜å†…å®¹ï¼Œè¾¹ç•Œä¸€å®šä¸è¦è¿‡å¤§ï¼Œå¯ä»¥é€‚å½“ç¼©å°ã€‚
   - é¢˜ç›®çš„åŒºåŸŸä¸å¯é‡å ã€‚
3. ç¡®ä¿è¯†åˆ«ç»“æœæŒ‰é¡ºåºæ’åˆ—
4. å¦‚æœæŸä¸ªé¢˜ç›®ä½ç½®ä¸å¤ªç¡®å®šï¼Œä»ç„¶è¦å°½é‡ç»™å‡ºä¼°è®¡ä½ç½®ï¼Œä½†å°†confidenceè®¾ç½®ä¸ºè¾ƒä½å€¼ï¼ˆå¦‚0.3-0.5ï¼‰
5. åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ å…¶ä»–è§£é‡Šæ–‡å­—

è¯·å¼€å§‹åˆ†æå›¾ç‰‡ï¼š"""

    def _parse_detection_result(
        self, response_text: str, practice_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """è§£æAIè¿”å›çš„æ£€æµ‹ç»“æœ"""
        try:
            self.logger.info(f"å¼€å§‹è§£æAIè¿”å›ç»“æœï¼ŒåŸå§‹é•¿åº¦: {len(response_text)}")

            # è®¡ç®—æœŸæœ›çš„é¢˜ç›®æ•°é‡
            expected_count = sum(
                len(section.get("questions", []))
                for section in practice_data.get("sections", [])
            )
            self.logger.info(f"æœŸæœ›è¯†åˆ« {expected_count} é“é¢˜ç›®")

            # æ¸…ç†å“åº”æ–‡æœ¬
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
                self.logger.info("ç§»é™¤äº†å¼€å¤´çš„```jsonæ ‡è®°")
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3]
                self.logger.info("ç§»é™¤äº†ç»“å°¾çš„```æ ‡è®°")
            clean_text = clean_text.strip()

            self.logger.info(f"æ¸…ç†åçš„æ–‡æœ¬é•¿åº¦: {len(clean_text)}")
            self.logger.debug(f"æ¸…ç†åçš„æ–‡æœ¬å†…å®¹: {clean_text[:200]}...")

            # è§£æJSONï¼ˆå¦‚æœä½¿ç”¨äº† JSON Schemaï¼Œåº”è¯¥å·²ç»æ˜¯ä¸¥æ ¼æ ¼å¼ï¼‰
            result = json.loads(clean_text)
            image_width = result.get("image_width", 1)
            image_height = result.get("image_height", 1)
            question_areas = result.get("question_areas", [])
            self.logger.info(f"å›¾ç‰‡å°ºå¯¸: {image_width}x{image_height}")
            self.logger.info(f"ä»JSONä¸­æå–åˆ° {len(question_areas)} ä¸ªé¢˜ç›®åŒºåŸŸ")

            # éªŒè¯å’Œæ¸…ç†ç»“æœ
            validated_areas = []
            for i, area in enumerate(question_areas):
                self.logger.debug(f"éªŒè¯é¢˜ç›®åŒºåŸŸ {i + 1}: {area}")
                if self._validate_question_area(area):
                    validated_areas.append(area)
                    self.logger.info(f"é¢˜ç›®åŒºåŸŸ {i + 1} éªŒè¯é€šè¿‡")
                else:
                    self.logger.warning(f"é¢˜ç›®åŒºåŸŸ {i + 1} éªŒè¯å¤±è´¥ï¼Œè·³è¿‡")

            self.logger.info(f"æœ€ç»ˆéªŒè¯é€šè¿‡ {len(validated_areas)} ä¸ªé¢˜ç›®åŒºåŸŸ")

            # æ£€æŸ¥è¯†åˆ«æ•°é‡æ˜¯å¦æ­£ç¡®
            if len(validated_areas) != expected_count:
                self.logger.warning(
                    f"âš ï¸ è¯†åˆ«åˆ°çš„é¢˜ç›®æ•°é‡({len(validated_areas)})ä¸æœŸæœ›æ•°é‡({expected_count})ä¸ä¸€è‡´ï¼"
                )
                self.logger.warning(
                    f"   æœŸæœ›: {expected_count} é“é¢˜ï¼Œå®é™…è¯†åˆ«: {len(validated_areas)} é“é¢˜"
                )
            else:
                self.logger.info(
                    f"âœ… é¢˜ç›®æ•°é‡åŒ¹é…ï¼šæˆåŠŸè¯†åˆ«æ‰€æœ‰ {expected_count} é“é¢˜ï¼"
                )

            return validated_areas

        except json.JSONDecodeError as e:
            self.logger.error(f"è§£ææ£€æµ‹ç»“æœJSONå¤±è´¥: {e}")
            self.logger.error(
                f"æ¸…ç†åçš„æ–‡æœ¬: {clean_text if 'clean_text' in locals() else 'N/A'}..."
            )
            self.logger.error(f"åŸå§‹å“åº”æ–‡æœ¬: {response_text[:]}...")
            return []
        except Exception as e:
            self.logger.error(f"è§£ææ£€æµ‹ç»“æœå¤±è´¥: {e}")
            import traceback

            self.logger.error(traceback.format_exc())
            return []

    def _validate_question_area(self, area: Dict[str, Any]) -> bool:
        """éªŒè¯é¢˜ç›®åŒºåŸŸæ•°æ®çš„æœ‰æ•ˆæ€§"""
        required_fields = ["question_number", "bbox_2d", "answer_bbox_2d"]

        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in required_fields:
            if field not in area:
                self.logger.warning(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False

        bbox_2d = area.get("bbox_2d", [])
        answer_bbox_2d = area.get("answer_bbox_2d", [])

        # æ£€æŸ¥bboxæ˜¯å¦ä¸ºé•¿åº¦ä¸º4çš„åˆ—è¡¨
        if not isinstance(bbox_2d, list) or len(bbox_2d) != 4:
            self.logger.warning(f"bbox_2dæ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºé•¿åº¦ä¸º4çš„åˆ—è¡¨: {bbox_2d}")
            return False

        if not isinstance(answer_bbox_2d, list) or len(answer_bbox_2d) != 4:
            self.logger.warning(
                f"answer_bbox_2dæ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºé•¿åº¦ä¸º4çš„åˆ—è¡¨: {answer_bbox_2d}"
            )
            return False

        try:
            if bbox_2d[0] >= bbox_2d[2] or bbox_2d[1] >= bbox_2d[3]:
                self.logger.warning(
                    f"bbox_2dåæ ‡é€»è¾‘é”™è¯¯: x1={bbox_2d[0]} >= x2={bbox_2d[2]} æˆ– y1={bbox_2d[1]} >= y2={bbox_2d[3]}"
                )
                return False

            if (
                answer_bbox_2d[0] >= answer_bbox_2d[2]
                or answer_bbox_2d[1] >= answer_bbox_2d[3]
            ):
                self.logger.warning(
                    f"answer_bbox_2dåæ ‡é€»è¾‘é”™è¯¯: x1={answer_bbox_2d[0]} >= x2={answer_bbox_2d[2]} æˆ– y1={answer_bbox_2d[1]} >= y2={answer_bbox_2d[3]}"
                )
                return False

        except (ValueError, TypeError) as e:
            self.logger.warning(f"åæ ‡å€¼è½¬æ¢å¤±è´¥: {e}")
            return False

        self.logger.debug(f"é¢˜ç›®åŒºåŸŸéªŒè¯é€šè¿‡: {area.get('question_number', 'N/A')}")
        return True
